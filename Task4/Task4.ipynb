{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import sys\n",
    "import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "sys.path.append('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_images = mnist.train_images()\n",
    "    train_labels = mnist.train_labels()\n",
    "\n",
    "    test_images = mnist.test_images()\n",
    "    test_labels = mnist.test_labels()\n",
    "\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "\n",
    "    x_train_shift = []\n",
    "    y_train_augmented = []\n",
    "    for dx, dy in ((-1, -1), (0, -1), (1, -1), (-1, 0), (0, 0), (1, 0), (-1, 1), (0, 1), (1, 1)):\n",
    "        for image, label in zip(train_images, train_labels):\n",
    "            x_train_shift.append(shift_image(image, dx, dy))\n",
    "            y_train_augmented.append(label)\n",
    "    x_train_shift = np.array(x_train_shift)\n",
    "    y_train_augmented = np.array(y_train_augmented)\n",
    "\n",
    "    print(x_train_shift.shape, y_train_augmented.shape, test_images.shape, test_labels.shape)\n",
    "\n",
    "    return x_train_shift, y_train_augmented, test_images, test_labels\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Reshape((28, 28, 1), name='reshape1'),\n",
    "        tf.keras.layers.Conv2D(8, [3, 3], strides=1, padding='SAME', name='conv1',\n",
    "                               input_shape=[28, 28, 1]),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=[3, 3], strides=2, name='pool1'),\n",
    "        tf.keras.layers.Conv2D(12, [3, 3], strides=1, padding='SAME', name='conv2'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=[3, 3], strides=2, name='pool2'),\n",
    "        tf.keras.layers.Conv2D(16, [3, 3], strides=1, padding='SAME', name='conv3'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=[3, 3], strides=2, name='pool3'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation=tf.nn.relu, name='fc1'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='output')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def shift_image(image, dx, dy):\n",
    "    image = image.reshape((28, 28))\n",
    "    shifted_image = shift(image, [dx, dy], cval=0, mode='constant')\n",
    "    return shifted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 36s 599us/sample - loss: 0.2766 - acc: 0.9132 - val_loss: 0.0854 - val_acc: 0.9724\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 36s 608us/sample - loss: 0.0976 - acc: 0.9704 - val_loss: 0.0530 - val_acc: 0.9835\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 37s 609us/sample - loss: 0.0751 - acc: 0.9771 - val_loss: 0.0449 - val_acc: 0.9860\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 37s 611us/sample - loss: 0.0612 - acc: 0.9813 - val_loss: 0.0458 - val_acc: 0.9849\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 37s 616us/sample - loss: 0.0550 - acc: 0.9829 - val_loss: 0.0497 - val_acc: 0.9845\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0497 - acc: 0.9845\n",
      "Test Acc =  0.9845\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = load_data()\n",
    "# X_train = mnist.train_images() / 255.0\n",
    "# Y_train = mnist.train_labels()\n",
    "# X_test = mnist.test_images() / 255.0\n",
    "# Y_test = mnist.test_labels()\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "log_dir=\".\\\\logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=5, validation_data=(X_test, Y_test), callbacks=[tensorboard_callback])\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print(\"Test Acc = \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_error = {}\n",
    "n_error = []\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] != Y_test[i]:\n",
    "        n_error.append(i)\n",
    "        if Y_test[i] in y_error.keys():\n",
    "            y_error[Y_test[i]] += 1\n",
    "        else:\n",
    "            y_error[Y_test[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(i, \":\", y_error[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(X_test[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1, (10,10))\n",
    "plt.subplots_adjust(wspace = 0.5, hspace = 0.5)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        n = n_error[i*4+j]\n",
    "        ax = plt.subplot(4, 4, i*4+j+1)\n",
    "        ax.set_title(\"pred:\" + str(y_pred[n]) +\" acc:\"+ str(Y_test[n]))\n",
    "        ax.imshow(X_test[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shift_test = []\n",
    "for dx, dy in ((-2, -2), (0, -2), (2, -2), (-2, 0), (0, 0), (2, 0), (-2, 2), (0, 2), (2, 2)):\n",
    "    x_shift_test.append(shift_image(X_train[100], dx, dy))\n",
    "\n",
    "plt.figure(1, (10,10))\n",
    "plt.subplots_adjust(wspace = 0.5, hspace = 0.5)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        n = i*3+j\n",
    "        ax = plt.subplot(3, 3, i*3+j+1)\n",
    "        ax.imshow(x_shift_test[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}